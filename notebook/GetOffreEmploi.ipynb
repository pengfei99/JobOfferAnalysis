{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# In this notebook, we will search some job offers from the french employment agency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-requise: Create an account for the french employment \n",
    "\n",
    "As documented on their website you need to:\n",
    "\n",
    "- Step1: Go to [pole-emploi](https://pole-emploi.io/create),create a new account and login\n",
    "- Step2: After login, Go to \"mon space\"->\"cree une application\" and agree to the terms of use. You need to provide three information\n",
    "    - Nom de l'application: You put a name of application that will consume this api e.g. toto\n",
    "    - URL d'accès: You put the url of your application. e.g. https://datalab.sspcloud.fr/home\n",
    "    - Description de votre application: Put the app description\n",
    "  After the creation, you should see the api ID and secret on the page \n",
    "- Step3: You will see a list of apis. Select the api that you are intrested in (e.g Infotravail, offre d'emploi) by clicking DEMANDE D'ACCÈS and selecting your application.\n",
    " \n",
    "For more information about the Pole-Emploi API subscription, read its [documentation](https://pole-emploi.io/data/api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offres_emploi import Api\n",
    "\n",
    "from offres_emploi.utils import dt_to_str_iso\n",
    "import datetime\n",
    "import pprint as pp\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import s3fs\n",
    "from pyarrow import fs\n",
    "import pyarrow as pa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get job offers by using key word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Build api client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Api(client_id=\"PAR_getjobs_9758a500d4c1f19834da4f62e3eedf94ff3ebf59cc5b38ad55fb0e96de9a5826\", \n",
    "            client_secret=\"903830b3dc3d9a6376f58eb12cb2bfe3c15ef7de4e45a662a531afcbd624b4bb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Set up search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = datetime.datetime(2020, 12, 1, 12, 30)\n",
    "end_dt = datetime.datetime.today()\n",
    "keyword=\"data\"\n",
    "params = {\n",
    "    \"motsCles\": keyword,\n",
    "    'minCreationDate': dt_to_str_iso(start_dt),\n",
    "    'maxCreationDate': dt_to_str_iso(end_dt),\n",
    "    # add filter to filter job by department \n",
    "    # 'department':'973',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Get job offers based on search filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making request with params {'motsCles': 'data', 'minCreationDate': '2020-12-01T12:30:00Z', 'maxCreationDate': '2021-11-30T14:30:10Z'}\n",
      "Token has not been requested yet. Requesting token\n",
      "Now requesting token\n",
      "{'accessibleTH': False,\n",
      " 'alternance': False,\n",
      " 'appellationlibelle': 'Data scientist',\n",
      " 'competences': [{'code': '109527',\n",
      "                  'exigence': 'S',\n",
      "                  'libelle': 'Adapter les outils de traitement statistique de '\n",
      "                             'données'},\n",
      "                 {'code': '109528',\n",
      "                  'exigence': 'S',\n",
      "                  'libelle': \"Rédiger l'information produite (études, \"\n",
      "                             'synthèses, rapports, bulletins, ...) et établir '\n",
      "                             'des prévisions, des évaluations, des '\n",
      "                             'recommandations, des perspectives, ...'},\n",
      "                 {'code': '109529',\n",
      "                  'exigence': 'S',\n",
      "                  'libelle': 'Présenter et diffuser les résultats des études '\n",
      "                             'réalisées'},\n",
      "                 {'code': '118732',\n",
      "                  'exigence': 'S',\n",
      "                  'libelle': 'Réaliser une veille documentaire (collecte, '\n",
      "                             'analyse etc.)'},\n",
      "                 {'code': '122609',\n",
      "                  'exigence': 'S',\n",
      "                  'libelle': 'Définir les méthodes et les outils de traitement '\n",
      "                             \"de l'information\"}],\n",
      " 'contact': {'coordonnees1': 'Pour postuler, utiliser le lien suivant : '\n",
      "                             'https://candidat.pole-emploi.fr/offres/recherche/detail/124GJFH',\n",
      "             'courriel': 'Pour postuler, utiliser le lien suivant : '\n",
      "                         'https://candidat.pole-emploi.fr/offres/recherche/detail/124GJFH',\n",
      "             'nom': 'EPSILON INGENIERIESA - Mme Anne THIEVENAZ'},\n",
      " 'dateActualisation': '2021-11-30T13:40:46.000Z',\n",
      " 'dateCreation': '2021-11-30T13:40:44.000Z',\n",
      " 'description': \"Crise sanitaire : L'employeur garantit une procédure de \"\n",
      "                'recrutement conforme aux recommandations gouvernementales.\\n'\n",
      "                'A compétences égales, le poste est ouvert aux personnes en '\n",
      "                'situation de handicap.\\n'\n",
      "                'Qui sommes-nous :\\n'\n",
      "                'EPSILON est une société du groupe ALCEN qui répond à '\n",
      "                \"différents besoins de conception et d'optimisation de \"\n",
      "                'systèmes pour les grands secteurs économiques. EPSILON mène '\n",
      "                'des études pour le perfectionnement des produits et services '\n",
      "                \"de ses clients ou pour ses propres technologies et s'engage \"\n",
      "                'sur des projets complexes de conception-réalisation avec le '\n",
      "                'support et la puissance du groupe ALCEN.\\n'\n",
      "                'EPSILON souhaite intensifier ses activités dans la région '\n",
      "                \"d'Aix en Provence et est à la recherche de femmes et hommes \"\n",
      "                'motivés pour rejoindre le groupe ALCEN, société familiale de '\n",
      "                '2500 personnes positionnée dans le domaine des technologies '\n",
      "                'de pointe.\\n'\n",
      "                'Ainsi, nous recherchons un(e) Ingénieur.e Informatique qui '\n",
      "                'aime relever les challenges avec créativité et pragmatisme et '\n",
      "                \"contribuer à la croissance rapide de l'entreprise.\\n\"\n",
      "                '\\n'\n",
      "                'Votre rôle :\\n'\n",
      "                'Vous intervenez sur les sujets de grands secteurs industriels '\n",
      "                '(Energie / Transport / Aerospace ) et tout au long des '\n",
      "                'différentes phases des projets : spécification, '\n",
      "                'développement, test, intégration de code. Vos missions sont '\n",
      "                'les suivantes :\\n'\n",
      "                '-\\tDévelopper les fonctionnalités spécifiées,\\n'\n",
      "                '-\\tConcevoir le codage et les tests unitaires de composants '\n",
      "                'logiciels,\\n'\n",
      "                \"-\\tAssurer l'intégration continue et la mise en configuration \"\n",
      "                'des applications,\\n'\n",
      "                '-\\tConduire les essais et validations en environnement '\n",
      "                'représentatif puis réel,\\n'\n",
      "                '-\\tMaintenir les applications réalisées et réaliser la '\n",
      "                'correction des anomalies éventuelles,\\n'\n",
      "                '-\\tRédiger la documentation technique,\\n'\n",
      "                '-\\tEffectuer une veille technologique.\\n'\n",
      "                '\\n'\n",
      "                'Votre profil :\\n'\n",
      "                \"De formation BAC+5, vous justifiez d'une première expérience \"\n",
      "                'réussie. Vous êtes passionné de nouvelles technologies et '\n",
      "                'suivez de près les innovations du moment. \\n'\n",
      "                \"L'utilisation des langages de programmation C/C++, Python, \"\n",
      "                'SQL sous différents environnements fait partie de votre '\n",
      "                'quotidien et vous maitrisez les architectures logicielles. \\n'\n",
      "                \"Vous maitrisez également l'anglais technique, ce qui vous \"\n",
      "                'permet de travailler sur des projets en anglais.\\n'\n",
      "                '\\n'\n",
      "                'De plus, vous êtes reconnu pour votre rigueur et votre esprit '\n",
      "                'de synthèse. Vous êtes également autonome et faites preuve '\n",
      "                \"d'un bon esprit d'équipe.\",\n",
      " 'dureeTravailLibelle': '35H Horaires normaux',\n",
      " 'dureeTravailLibelleConverti': 'Temps plein',\n",
      " 'entreprise': {'description': 'Historiquement spécialiste dans le domaine de '\n",
      "                               'la recherche et développement en thermique '\n",
      "                               'pour les secteurs aéronautique et spatial, '\n",
      "                               'EPSILON se diversifie.\\n'\n",
      "                               '\\n'\n",
      "                               'Ainsi, depuis plus de deux ans, EPSILON répond '\n",
      "                               'aux enjeux de nouveaux secteurs (énergie, '\n",
      "                               'transport dé-carboné, santé) par des '\n",
      "                               'compétences alliant le monde de la physique et '\n",
      "                               'le digital. \\n',\n",
      "                'entrepriseAdaptee': False,\n",
      "                'logo': 'https://entreprise.pole-emploi.fr/static/img/logos/lM4Pauwq0qnyXXHP5UdJIFBrIVezURTv.png',\n",
      "                'nom': 'EPSILON INGENIERIESA',\n",
      "                'url': 'http://www.epsilon-alcen.com/fr'},\n",
      " 'experienceExige': 'D',\n",
      " 'experienceLibelle': 'Débutant accepté',\n",
      " 'id': '124GJFH',\n",
      " 'intitule': 'Ingénieur Data Science  (H/F)',\n",
      " 'lieuTravail': {'codePostal': '13090',\n",
      "                 'commune': '13001',\n",
      "                 'latitude': 43.539537,\n",
      "                 'libelle': '13 - AIX EN PROVENCE',\n",
      "                 'longitude': 5.40142},\n",
      " 'natureContrat': 'Contrat travail',\n",
      " 'nombrePostes': 1,\n",
      " 'offresManqueCandidats': False,\n",
      " 'origineOffre': {'origine': '1',\n",
      "                  'urlOrigine': 'https://candidat.pole-emploi.fr/offres/recherche/detail/124GJFH'},\n",
      " 'qualificationCode': '9',\n",
      " 'qualificationLibelle': 'Cadre',\n",
      " 'qualitesProfessionnelles': [{'description': 'Capacité à être proactif, à '\n",
      "                                              'initier, à imaginer des '\n",
      "                                              'propositions nouvelles pour '\n",
      "                                              'résoudre les problèmes '\n",
      "                                              'identifiés ou pour améliorer '\n",
      "                                              'une situation. Exemple : '\n",
      "                                              'proposer des améliorations, '\n",
      "                                              'être positif et constructif',\n",
      "                               'libelle': 'Force de proposition'},\n",
      "                              {'description': 'Capacité à prendre en charge '\n",
      "                                              'son activité sans devoir être '\n",
      "                                              'encadré de façon continue. '\n",
      "                                              'Exemple : travailler '\n",
      "                                              'efficacement sans responsable',\n",
      "                               'libelle': 'Autonomie'},\n",
      "                              {'description': 'Capacité à respecter les règles '\n",
      "                                              \"et codes de l'entreprise, à \"\n",
      "                                              'réaliser des tâches en suivant '\n",
      "                                              'avec précision les procédures '\n",
      "                                              'et instructions fournies , à '\n",
      "                                              'transmettre des informations '\n",
      "                                              'avec exactitude. Exemple : être '\n",
      "                                              'ponctuel, respecter les '\n",
      "                                              'engagements, résister à la '\n",
      "                                              'distraction',\n",
      "                               'libelle': 'Rigueur'}],\n",
      " 'romeCode': 'M1403',\n",
      " 'romeLibelle': 'Études et prospectives socio-économiques',\n",
      " 'salaire': {'commentaire': 'à négocier', 'complement1': 'Autre'},\n",
      " 'secteurActivite': '62',\n",
      " 'secteurActiviteLibelle': 'Conseil en systèmes et logiciels informatiques',\n",
      " 'typeContrat': 'CDI',\n",
      " 'typeContratLibelle': 'Contrat à durée indéterminée'}\n"
     ]
    }
   ],
   "source": [
    "search_on_big_data = client.search(params=params)\n",
    "\n",
    "# Get the first element of the result\n",
    "pp.pprint(search_on_big_data[\"resultats\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: <class 'dict'>\n",
      "It contains Keys: dict_keys(['resultats', 'filtresPossibles', 'Content-Range'])\n",
      "{'first_index': '0', 'last_index': '149', 'max_results': '1040'}\n",
      "[{'filtre': 'typeContrat', 'agregation': [{'valeurPossible': 'CDD', 'nbResultats': 88}, {'valeurPossible': 'CDI', 'nbResultats': 919}, {'valeurPossible': 'MIS', 'nbResultats': 33}]}, {'filtre': 'experience', 'agregation': [{'valeurPossible': '0', 'nbResultats': 184}, {'valeurPossible': '1', 'nbResultats': 340}, {'valeurPossible': '2', 'nbResultats': 393}, {'valeurPossible': '3', 'nbResultats': 123}]}, {'filtre': 'qualification', 'agregation': [{'valeurPossible': '0', 'nbResultats': 65}, {'valeurPossible': '9', 'nbResultats': 214}, {'valeurPossible': 'X', 'nbResultats': 761}]}, {'filtre': 'natureContrat', 'agregation': [{'valeurPossible': 'E1', 'nbResultats': 992}, {'valeurPossible': 'E2', 'nbResultats': 37}, {'valeurPossible': 'FS', 'nbResultats': 10}, {'valeurPossible': 'FV', 'nbResultats': 1}]}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# analyze the response\n",
    "print(f\"Response type: {type(search_on_big_data)}\")\n",
    "# We can see response is a dict\n",
    "print(f\"It contains Keys: {search_on_big_data.keys()}\")\n",
    "print(search_on_big_data[\"Content-Range\"])\n",
    "print(search_on_big_data[\"filtresPossibles\"])\n",
    "print(type(search_on_big_data[\"resultats\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice the reponse is a dictionary that has three keys:\n",
    "- resultats(list): This list contains all job offers that in the range  \n",
    "- filtresPossibles(dict): Stats pre-calculated, for instance in a list of resultats it has 88 CDD, and 920 CDI. \n",
    "- Content-Range(dict): Note the api will send back 1150 row at max (if it exists that much). And the 1150 row is organized by a pagination of 150 rows. And in one reponse it only has the row specified in the range. So we need to use **Range** paramètre such as 0-149, 150-299 etc. to get all the results \n",
    "\n",
    "As a result, we need a function to loop over all possible range to get all possible rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_result_by_range(client, params:dict, range_min:int, range_max:int):\n",
    "    # add range to filter\n",
    "    range_str=f\"{str(range_min)}-{str(range_max)}\"\n",
    "    params[\"range\"]=range_str\n",
    "    response=client.search(params=params)\n",
    "    return response[\"resultats\"]\n",
    "\n",
    "def get_all_search_result(client, params:dict):\n",
    "    response=client.search(params=params)\n",
    "    total_response_num=int(response[\"Content-Range\"][\"max_results\"])\n",
    "    total=[]\n",
    "    index=0\n",
    "    while total_response_num>150:\n",
    "        total_response_num=total_response_num-150\n",
    "        tmp=get_search_result_by_range(client, params, index, index+149)\n",
    "        index=index+150\n",
    "        for item in tmp:\n",
    "            total.append(item)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making request with params {'motsCles': 'data', 'minCreationDate': '2020-12-01T12:30:00Z', 'maxCreationDate': '2021-11-30T14:30:10Z'}\n",
      "Making request with params {'motsCles': 'data', 'minCreationDate': '2020-12-01T12:30:00Z', 'maxCreationDate': '2021-11-30T14:30:10Z', 'range': '0-149'}\n",
      "Making request with params {'motsCles': 'data', 'minCreationDate': '2020-12-01T12:30:00Z', 'maxCreationDate': '2021-11-30T14:30:10Z', 'range': '150-299'}\n",
      "Making request with params {'motsCles': 'data', 'minCreationDate': '2020-12-01T12:30:00Z', 'maxCreationDate': '2021-11-30T14:30:10Z', 'range': '300-449'}\n",
      "Making request with params {'motsCles': 'data', 'minCreationDate': '2020-12-01T12:30:00Z', 'maxCreationDate': '2021-11-30T14:30:10Z', 'range': '450-599'}\n",
      "Making request with params {'motsCles': 'data', 'minCreationDate': '2020-12-01T12:30:00Z', 'maxCreationDate': '2021-11-30T14:30:10Z', 'range': '600-749'}\n",
      "Making request with params {'motsCles': 'data', 'minCreationDate': '2020-12-01T12:30:00Z', 'maxCreationDate': '2021-11-30T14:30:10Z', 'range': '750-899'}\n"
     ]
    }
   ],
   "source": [
    "total=get_all_search_result(client,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898\n",
      "{'accessibleTH': False,\n",
      " 'alternance': True,\n",
      " 'appellationlibelle': 'Data scientist',\n",
      " 'dateActualisation': '2021-09-27T12:22:00.000Z',\n",
      " 'dateCreation': '2021-09-27T12:22:00.000Z',\n",
      " 'description': 'Mener les études préalables au développement des actions '\n",
      "                'marketing (étude de marché, positionnement concurrence, '\n",
      "                'bonnes pratiques sur le territoire et hors territoire). '\n",
      "                \"Assurer le suivi et l'analyse des offres ainsi que des \"\n",
      "                'résultats commerciaux tous marchés. Mettre en œuvre les '\n",
      "                'modèles CRM analytiques et opérationnels liés aux actions à '\n",
      "                \"mener, sur l'ensemble des canaux de communication. Assurer le \"\n",
      "                \"suivi et l'analyse des résultats commerciaux sur tous les \"\n",
      "                \"marchés. Participer à l'élaboration du Plan de Développement \"\n",
      "                'Annuel. Participer à la mise en oeuvre des outils marketing '\n",
      "                \"(scores, segmentations, suivi d'action.) afin d'approfondir \"\n",
      "                'la connaissance client et optimiser les dispositifs de '\n",
      "                'Gestion de la Relation des Caisses Régionales (ciblages, '\n",
      "                'modélisations, webtracking.). Assurer la veille technique '\n",
      "                \"relative à l'évolution des outils et l'efficacité des offres \"\n",
      "                'et des canaux de distribution. Contrôler la qualité de la '\n",
      "                'production du service rendu en veillant à la prise en compte '\n",
      "                'des attentes des interlocuteurs internes et externes. - '\n",
      "                'Formation type master II ou équivalent en '\n",
      "                'statistiques/mathématiques appliquées ou informatique '\n",
      "                'appliquée - Connaissance des méthodes et outils de traitement '\n",
      "                'et analyse des données (SAS, R, SQL, Python .) - Disposition '\n",
      "                \"pour l'apprentissage de nouveaux outils. - Appétence pour le \"\n",
      "                \"digital. - Compétences générales en IT. - Capacité d'analyse \"\n",
      "                \"et de synthèse. - Capacité à construire l'information \"\n",
      "                \"développée au sein de l'unité de façon rationalisée. - Force \"\n",
      "                \"de proposition. - Capacité d'écoute et d'adaptation. - \"\n",
      "                'Aptitude à travailler en équipe et à conduire des projets. - '\n",
      "                'Expérience souhaitée 3 à 5 ans. Votre contrat: '\n",
      "                '33K€intéressement et avantages ',\n",
      " 'entreprise': {'entrepriseAdaptee': False},\n",
      " 'experienceExige': 'E',\n",
      " 'experienceLibelle': 'Expérience exigée de 3 An(s)',\n",
      " 'id': '2370055',\n",
      " 'intitule': 'Data scientist H/F',\n",
      " 'lieuTravail': {'libelle': 'Occitanie'},\n",
      " 'natureContrat': 'Contrat apprentissage',\n",
      " 'nombrePostes': 1,\n",
      " 'origineOffre': {'origine': '2',\n",
      "                  'partenaires': [{'logo': 'https://www.pole-emploi.fr/static/img/partenaires/adzuna80.png',\n",
      "                                   'nom': 'ADZUNA',\n",
      "                                   'url': 'https://www.adzuna.fr/details/2478292417?v=85AE1C24F9DDDFFF1F7082341BAED89A55D5E7A3&utm_source=polemploi&utm_medium=organic&chnlid=126'}],\n",
      "                  'urlOrigine': 'https://candidat.pole-emploi.fr/offres/recherche/detail/2370055'},\n",
      " 'romeCode': 'M1403',\n",
      " 'romeLibelle': 'Études et prospectives socio-économiques',\n",
      " 'salaire': {},\n",
      " 'typeContrat': 'CDI',\n",
      " 'typeContratLibelle': 'Contrat à durée indéterminée'}\n"
     ]
    }
   ],
   "source": [
    "print(len(total))\n",
    "pp.pprint(total[897])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Generate data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use json normalize to convert json file to a pandas dataframe\n",
    "df = pd.json_normalize(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>intitule</th>\n",
       "      <th>description</th>\n",
       "      <th>dateCreation</th>\n",
       "      <th>dateActualisation</th>\n",
       "      <th>romeCode</th>\n",
       "      <th>romeLibelle</th>\n",
       "      <th>appellationlibelle</th>\n",
       "      <th>typeContrat</th>\n",
       "      <th>typeContratLibelle</th>\n",
       "      <th>...</th>\n",
       "      <th>contact.coordonnees3</th>\n",
       "      <th>agence.courriel</th>\n",
       "      <th>experienceCommentaire</th>\n",
       "      <th>contact.urlPostulation</th>\n",
       "      <th>deplacementCode</th>\n",
       "      <th>deplacementLibelle</th>\n",
       "      <th>salaire.complement2</th>\n",
       "      <th>contact.commentaire</th>\n",
       "      <th>complementExercice</th>\n",
       "      <th>conditionExercice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124GJFH</td>\n",
       "      <td>Ingénieur Data Science  (H/F)</td>\n",
       "      <td>Crise sanitaire : L'employeur garantit une pro...</td>\n",
       "      <td>2021-11-30T13:40:44.000Z</td>\n",
       "      <td>2021-11-30T13:40:46.000Z</td>\n",
       "      <td>M1403</td>\n",
       "      <td>Études et prospectives socio-économiques</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5762522</td>\n",
       "      <td>Data Analyst H/F</td>\n",
       "      <td>Créé en 2009, INELYS s'est organisé par pôles...</td>\n",
       "      <td>2021-11-30T12:42:59.000Z</td>\n",
       "      <td>2021-11-30T12:42:59.000Z</td>\n",
       "      <td>M1403</td>\n",
       "      <td>Études et prospectives socio-économiques</td>\n",
       "      <td>Data analyst</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5762422</td>\n",
       "      <td>Manager de Projet Data hf H/F</td>\n",
       "      <td>Votre missionBadenoch + Clark, cabinet de cons...</td>\n",
       "      <td>2021-11-30T12:42:36.000Z</td>\n",
       "      <td>2021-11-30T12:42:36.000Z</td>\n",
       "      <td>M1802</td>\n",
       "      <td>Expertise et support en systèmes d'information</td>\n",
       "      <td>Data manager</td>\n",
       "      <td>CDD</td>\n",
       "      <td>Contrat à durée déterminée - 8 Mois</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5762278</td>\n",
       "      <td>Data Analyst ESGRSE HF H/F</td>\n",
       "      <td>Description du poste Rattaché à la Direction G...</td>\n",
       "      <td>2021-11-30T12:42:08.000Z</td>\n",
       "      <td>2021-11-30T12:42:08.000Z</td>\n",
       "      <td>M1403</td>\n",
       "      <td>Études et prospectives socio-économiques</td>\n",
       "      <td>Data analyst</td>\n",
       "      <td>CDD</td>\n",
       "      <td>Contrat à durée déterminée - 8 Mois</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5761328</td>\n",
       "      <td>Stage Data Analyst H/F</td>\n",
       "      <td>TRANSITIONS est une agence de conseil en dével...</td>\n",
       "      <td>2021-11-30T12:39:12.000Z</td>\n",
       "      <td>2021-11-30T12:39:12.000Z</td>\n",
       "      <td>M1403</td>\n",
       "      <td>Études et prospectives socio-économiques</td>\n",
       "      <td>Data analyst</td>\n",
       "      <td>CDD</td>\n",
       "      <td>Contrat à durée déterminée - 8 Mois</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       intitule  \\\n",
       "0  124GJFH  Ingénieur Data Science  (H/F)   \n",
       "1  5762522               Data Analyst H/F   \n",
       "2  5762422  Manager de Projet Data hf H/F   \n",
       "3  5762278     Data Analyst ESGRSE HF H/F   \n",
       "4  5761328         Stage Data Analyst H/F   \n",
       "\n",
       "                                         description  \\\n",
       "0  Crise sanitaire : L'employeur garantit une pro...   \n",
       "1   Créé en 2009, INELYS s'est organisé par pôles...   \n",
       "2  Votre missionBadenoch + Clark, cabinet de cons...   \n",
       "3  Description du poste Rattaché à la Direction G...   \n",
       "4  TRANSITIONS est une agence de conseil en dével...   \n",
       "\n",
       "               dateCreation         dateActualisation romeCode  \\\n",
       "0  2021-11-30T13:40:44.000Z  2021-11-30T13:40:46.000Z    M1403   \n",
       "1  2021-11-30T12:42:59.000Z  2021-11-30T12:42:59.000Z    M1403   \n",
       "2  2021-11-30T12:42:36.000Z  2021-11-30T12:42:36.000Z    M1802   \n",
       "3  2021-11-30T12:42:08.000Z  2021-11-30T12:42:08.000Z    M1403   \n",
       "4  2021-11-30T12:39:12.000Z  2021-11-30T12:39:12.000Z    M1403   \n",
       "\n",
       "                                      romeLibelle appellationlibelle  \\\n",
       "0        Études et prospectives socio-économiques     Data scientist   \n",
       "1        Études et prospectives socio-économiques       Data analyst   \n",
       "2  Expertise et support en systèmes d'information       Data manager   \n",
       "3        Études et prospectives socio-économiques       Data analyst   \n",
       "4        Études et prospectives socio-économiques       Data analyst   \n",
       "\n",
       "  typeContrat                   typeContratLibelle  ... contact.coordonnees3  \\\n",
       "0         CDI         Contrat à durée indéterminée  ...                  NaN   \n",
       "1         CDI         Contrat à durée indéterminée  ...                  NaN   \n",
       "2         CDD  Contrat à durée déterminée - 8 Mois  ...                  NaN   \n",
       "3         CDD  Contrat à durée déterminée - 8 Mois  ...                  NaN   \n",
       "4         CDD  Contrat à durée déterminée - 8 Mois  ...                  NaN   \n",
       "\n",
       "  agence.courriel experienceCommentaire contact.urlPostulation  \\\n",
       "0             NaN                   NaN                    NaN   \n",
       "1             NaN                   NaN                    NaN   \n",
       "2             NaN                   NaN                    NaN   \n",
       "3             NaN                   NaN                    NaN   \n",
       "4             NaN                   NaN                    NaN   \n",
       "\n",
       "  deplacementCode deplacementLibelle  salaire.complement2  \\\n",
       "0             NaN                NaN                  NaN   \n",
       "1             NaN                NaN                  NaN   \n",
       "2             NaN                NaN                  NaN   \n",
       "3             NaN                NaN                  NaN   \n",
       "4             NaN                NaN                  NaN   \n",
       "\n",
       "   contact.commentaire  complementExercice conditionExercice  \n",
       "0                  NaN                 NaN               NaN  \n",
       "1                  NaN                 NaN               NaN  \n",
       "2                  NaN                 NaN               NaN  \n",
       "3                  NaN                 NaN               NaN  \n",
       "4                  NaN                 NaN               NaN  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Write data frame to S3 as parquet\n",
    "\n",
    "We have the data frame, now we want to save the data frame on s3. We want to save the data frame in format **parquet**. Because it has an integrated schema.\n",
    "\n",
    "### 5.1 Configure s3 connection\n",
    "\n",
    "Here we will set the s3 credential and the output path of the parquet file. As we will generate a parquet file each day. We would like to have the generation date inside the file name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.environ['AWS_S3_ENDPOINT']\n",
    "bucket = \"pengfei\"\n",
    "current_date=datetime.date.today().strftime(\"%d-%m-%Y\")\n",
    "output_path = f\"diffusion/demo_prod/job_offer_{current_date}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Write df to s3 as parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function write a pandas dataframe to s3 in parquet format\n",
    "def write_df_to_s3(df, endpoint, bucket_name, path):\n",
    "    # Convert pandas df to Arrow table\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    url = f\"https://{endpoint}\"\n",
    "    fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': url})\n",
    "    file_uri = f\"{bucket_name}/{path}\"\n",
    "    pq.write_to_dataset(table, root_path=file_uri, filesystem=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df_to_s3(df,endpoint,bucket,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the output parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function read a parquet file and return a arrow table\n",
    "def read_parquet_from_s3(endpoint: str, bucket_name, path):\n",
    "    url = f\"https://{endpoint}\"\n",
    "    fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': url})\n",
    "    file_uri = f\"{bucket_name}/{path}\"\n",
    "    str_info = fs.info(file_uri)\n",
    "    print(f\"input file metadata: {str_info}\")\n",
    "    dataset = pq.ParquetDataset(file_uri, filesystem=fs)\n",
    "    table = dataset.read()\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
